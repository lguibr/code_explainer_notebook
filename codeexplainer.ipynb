{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4afb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.10/site-packages (0.0.145)\n",
      "Requirement already satisfied: deeplake in ./venv/lib/python3.10/site-packages (3.2.22)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.10/site-packages (0.27.4)\n",
      "Requirement already satisfied: gitpython in ./venv/lib/python3.10/site-packages (3.1.31)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: python-magic in ./venv/lib/python3.10/site-packages (0.4.27)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./venv/lib/python3.10/site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in ./venv/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in ./venv/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in ./venv/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./venv/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in ./venv/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./venv/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./venv/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in ./venv/lib/python3.10/site-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in ./venv/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: boto3 in ./venv/lib/python3.10/site-packages (from deeplake) (1.24.59)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from deeplake) (8.1.3)\n",
      "Requirement already satisfied: humbug>=0.3.1 in ./venv/lib/python3.10/site-packages (from deeplake) (0.3.1)\n",
      "Requirement already satisfied: numcodecs in ./venv/lib/python3.10/site-packages (from deeplake) (0.11.0)\n",
      "Requirement already satisfied: pathos in ./venv/lib/python3.10/site-packages (from deeplake) (0.3.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (from deeplake) (9.5.0)\n",
      "Requirement already satisfied: pyjwt in ./venv/lib/python3.10/site-packages (from deeplake) (2.6.0)\n",
      "Requirement already satisfied: aioboto3==10.4.0 in ./venv/lib/python3.10/site-packages (from deeplake) (10.4.0)\n",
      "Requirement already satisfied: nest_asyncio in ./venv/lib/python3.10/site-packages (from deeplake) (1.5.6)\n",
      "Requirement already satisfied: aiobotocore[boto3]==2.4.2 in ./venv/lib/python3.10/site-packages (from aioboto3==10.4.0->deeplake) (2.4.2)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in ./venv/lib/python3.10/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.15.0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in ./venv/lib/python3.10/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (0.11.0)\n",
      "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in ./venv/lib/python3.10/site-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.27.59)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venv/lib/python3.10/site-packages (from gitpython) (4.0.10)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.10/site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in ./venv/lib/python3.10/site-packages (from boto3->deeplake) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./venv/lib/python3.10/site-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./venv/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: entrypoints in ./venv/lib/python3.10/site-packages (from numcodecs->deeplake) (0.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in ./venv/lib/python3.10/site-packages (from pathos->deeplake) (0.70.14)\n",
      "Requirement already satisfied: dill>=0.3.6 in ./venv/lib/python3.10/site-packages (from pathos->deeplake) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in ./venv/lib/python3.10/site-packages (from pathos->deeplake) (0.3.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in ./venv/lib/python3.10/site-packages (from pathos->deeplake) (1.7.6.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./venv/lib/python3.10/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (2.8.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary Python libraries\n",
    "!python3 -m pip install --upgrade langchain deeplake openai gitpython tiktoken python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b1172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAi Token:········\n",
      "Activeloop Token:········\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "from getpass import getpass\n",
    "from git import Repo\n",
    "\n",
    "# Set up API keys\n",
    "os.environ['OPENAI_API_KEY'] = getpass(\"OpenAi Token:\")\n",
    "os.environ['ACTIVELOOP_TOKEN'] = getpass('Activeloop Token:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1920aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clone repository\n",
    "def clone_repository(github_user, reponame, branch='main'):\n",
    "    repo_url = f'https://github.com/{github_user}/{reponame}.git'\n",
    "    local_path = os.path.join('.', reponame)\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        shutil.rmtree(local_path)\n",
    "    \n",
    "    repo = Repo.clone_from(repo_url, local_path, branch=branch)\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f59b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "github_user = 'lguibr'\n",
    "reponame = 'pongo'\n",
    "branch = 'main' # Optional, defaults to 'main'\n",
    "local_path = clone_repository(github_user, reponame, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "import magic\n",
    "\n",
    "root_dir = local_path\n",
    "\n",
    "ignored_paths = [\n",
    "    '.git',\n",
    "    '/.venv/',\n",
    "    # Add more paths to ighere\n",
    "]\n",
    "\n",
    "\n",
    "def is_text_file(filepath):\n",
    "    file_type = magic.from_file(filepath)\n",
    "    return 'text' in file_type\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    print(f\"Directory: {dirpath}\")\n",
    "    if any(ignored_path in dirpath for ignored_path in ignored_paths):\n",
    "        print(f\"Ignoring the directory: {dirpath}\")\n",
    "        continue  # Skip this directory if it contains an ignored path\n",
    "\n",
    "    for file in filenames:\n",
    "        filepath = os.path.join(dirpath, file)\n",
    "        if is_text_file(filepath):\n",
    "            print(f\"Loading file: {file}\")\n",
    "            try:\n",
    "                loader = TextLoader(filepath, encoding='utf-8')\n",
    "                \n",
    "                content = loader.load_and_split()\n",
    "                print(f'filepath:\\n{filepath}\\n')\n",
    "                docs.extend(content)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file: {file}, error: {e}\")\n",
    "                pass\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66ad23c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 41 texts\n"
     ]
    }
   ],
   "source": [
    "# Split documents\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=4000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# After splitting documents\n",
    "print(f\"Created {len(texts)} texts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "971eb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steup DEEPLAKE_ACCOUNT_NAME\n",
    "\n",
    "DEEPLAKE_ACCOUNT_NAME=\"lgpelin92\"\n",
    "DATASET_NAME=\"pongo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc8fed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/lgpelin92/pongo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://lgpelin92/pongo loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00\n",
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://lgpelin92/pongo', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape      dtype  compression\n",
      "  -------   -------   -------    -------  ------- \n",
      " embedding  generic  (41, 1536)  float32   None   \n",
      "    ids      text     (41, 1)      str     None   \n",
      " metadata    json     (41, 1)      str     None   \n",
      "   text      text     (41, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "db = DeepLake.from_documents(texts, embeddings, dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/{DATASET_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d807c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/lgpelin92/pongo\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://lgpelin92/pongo loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r",
      "\r",
      " \r",
      "Deep Lake Dataset in hub://lgpelin92/pongo already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://lgpelin92/pongo', read_only=True, tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape      dtype  compression\n",
      "  -------   -------   -------    -------  ------- \n",
      " embedding  generic  (41, 1536)  float32   None   \n",
      "    ids      text     (41, 1)      str     None   \n",
      " metadata    json     (41, 1)      str     None   \n",
      "   text      text     (41, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain and DeepLake\n",
    "db = DeepLake(dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/{DATASET_NAME}\", read_only=True, embedding_function=embeddings)\n",
    "\n",
    "model='gpt-4'\n",
    "timeout=6000\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=model,\n",
    "    timeout=timeout,\n",
    "    streaming=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,   \n",
    ")\n",
    "\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4bcd4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Chat history:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-> **Question**: Write a test for player connecting to the game"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**: Here's a test for player connecting to the game:\n",
       "\n",
       "```go\n",
       "package game\n",
       "\n",
       "import (\n",
       "\t\"testing\"\n",
       "\n",
       "\t\"github.com/stretchr/testify/assert\"\n",
       ")\n",
       "\n",
       "func TestPlayerConnect(t *testing.T) {\n",
       "\tcanvas := &Canvas{Width: 800, Height: 800}\n",
       "\tplayerChannel := NewPlayerChannel()\n",
       "\tplayer := NewPlayer(canvas, 1, playerChannel)\n",
       "\n",
       "\tgo func() {\n",
       "\t\tplayer.Connect()\n",
       "\t}()\n",
       "\n",
       "\tvar connected bool\n",
       "\tselect {\n",
       "\tcase msg := <-playerChannel:\n",
       "\t\tconnectedMsg, ok := msg.(PlayerConnectMessage)\n",
       "\t\tif !ok {\n",
       "\t\t\tt.Errorf(\"Expected PlayerConnectMessage, got %T\", msg)\n",
       "\t\t\treturn\n",
       "\t\t}\n",
       "\t\tassert.Equal(t, player, connectedMsg.PlayerPayload, \"Expected connected player payload to be the same as player\")\n",
       "\t\tconnected = true\n",
       "\tdefault:\n",
       "\t\tconnected = false\n",
       "\t}\n",
       "\n",
       "\tif !connected {\n",
       "\t\tt.Errorf(\"Expected player to connect, but did not receive a PlayerConnectMessage\")\n",
       "\t}\n",
       "}\n",
       "```\n",
       "\n",
       "This test checks the functionality of the `Connect` method of the `Player` struct. It creates a `Canvas` and a `PlayerChannel` to initialize a new `Player` instance. Then, it calls the `Connect` method in a goroutine and listens for a `PlayerConnectMessage` on the `PlayerChannel`. If a `PlayerConnectMessage` is received, it checks whether the `PlayerPayload` in the message is the same as the created `Player`. If the message is not received, the test fails.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Click here to download chat history: <a href='chat_history.txt' target='_blank'>chat_history.txt</a><br>"
      ],
      "text/plain": [
       "/home/lg/Lab/jupiter/chat_history.txt"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, FileLink, clear_output\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter your question (type 'exit' to quit): \")\n",
    "    \n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "    clear_output()\n",
    "    display(Markdown(f\"-> **Question**: {question}\"))\n",
    "    display(Markdown(f\"**Answer**:\"))\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    answer = result['answer']\n",
    "    clear_output()\n",
    "    display(Markdown(f\"-> **Question**: {question}\"))\n",
    "    display(Markdown(f\"**Answer**: {answer}\\n\"))\n",
    "    \n",
    "    chat_history.append((question, answer))\n",
    "\n",
    "clear_output()    \n",
    "display(Markdown(\"\\nChat history:\"))\n",
    "\n",
    "for q, a in chat_history:\n",
    "    display(Markdown(f\"-> **Question**: {q}\"))\n",
    "    display(Markdown(f\"**Answer**: {a}\\n\"))\n",
    "        \n",
    "## Save chat_history to a text file\n",
    "filename = \"chat_history.txt\"\n",
    "with open(filename, \"w\") as f:\n",
    "    for q, a in chat_history:\n",
    "        f.write(f\"-> **Question**: {q}\\n\")\n",
    "        f.write(f\"**Answer**: {a}\\n\\n\")\n",
    "\n",
    "# Offer user to download the file\n",
    "FileLink(filename, result_html_prefix=\"Click here to download chat history: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2bcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
